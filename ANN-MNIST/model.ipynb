{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600318508497",
   "display_name": "Python 3.7.7 64-bit ('py37': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "source": [
    "# Data Generators"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# download mnist dataset in local directory\n",
    "train = datasets.MNIST(\"\", train=True, download=True,\n",
    "                       transform=transforms.Compose([transforms.ToTensor()]))\n",
    "# we specify all transforms we have to apply in transforms.Compose([])\n",
    "test = datasets.MNIST(\"\", train=False, download=True,\n",
    "                      transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "trainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(test, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.]]],\n\n\n        [[[0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.]]],\n\n\n        [[[0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.]]],\n\n\n        ...,\n\n\n        [[[0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.]]],\n\n\n        [[[0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.]]],\n\n\n        [[[0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([9, 0, 4, 8, 4, 7, 6, 6, 1, 6])]\n"
    }
   ],
   "source": [
    "for data in trainset:\n",
    "    # print one batch of dataset\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([1, 28, 28])\ntensor(9)\n"
    }
   ],
   "source": [
    "x, y = data[0][0], data[1][0]\n",
    "print(data[0][0].shape)\n",
    "print(y)\n",
    "# shape of object is (1, 28, 28) but we need (28, 28) for displaying"
   ]
  },
  {
   "source": [
    "# Data Cleaning\n",
    "\n",
    "Checking if the dataset is balanced because if we have 70% of our dataset only as one number then the neural network will always keep predicting that number and we won't be able to get out of this hole no matter how much we train because the model will figure out the quickest way to reduce loss is by predicting that number as most of the dataset predicts that number."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0: 9.871666666666666\n1: 11.236666666666666\n2: 9.93\n3: 10.218333333333334\n4: 9.736666666666666\n5: 9.035\n6: 9.863333333333333\n7: 10.441666666666666\n8: 9.751666666666667\n9: 9.915000000000001\n"
    }
   ],
   "source": [
    "total = 0\n",
    "counter_dict = {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}\n",
    "for data in trainset:\n",
    "    Xs, ys = data\n",
    "    for y in ys:\n",
    "        counter_dict[int(y)] += 1\n",
    "        total += 1\n",
    "for i in counter_dict:\n",
    "    print(f\"{i}: {counter_dict[i]/total*100}\")"
   ]
  },
  {
   "source": [
    "# Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "running on the gpu\n"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(\"running on the gpu\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"running on the cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Net(\n  (fc1): Linear(in_features=784, out_features=64, bias=True)\n  (fc2): Linear(in_features=64, out_features=64, bias=True)\n  (fc3): Linear(in_features=64, out_features=64, bias=True)\n  (fc4): Linear(in_features=64, out_features=10, bias=True)\n)\n"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # initializes nn.Module class\n",
    "        self.fc1 = nn.Linear(784, 64)\n",
    "        # 784 after flattening image - 28x28(flatten because it is an ann not cnn)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # we can insert logic in this forward function using if statements etc.\n",
    "        X = F.relu(self.fc1(X))\n",
    "        X = F.relu(self.fc2(X))\n",
    "        X = F.relu(self.fc3(X))\n",
    "        X = self.fc4(X)\n",
    "        return F.log_softmax(X, dim=1)\n",
    "        # perform softmax on output layer (dim = 1 is axes)\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[-2.2340, -2.2474, -2.3792, -2.4804, -2.3623, -2.3531, -2.2776, -2.1942,\n         -2.3303, -2.2038]], grad_fn=<LogSoftmaxBackward>)\n"
    }
   ],
   "source": [
    "# try out model\n",
    "X = torch.rand((28, 28))\n",
    "X = X.view(-1, 28*28)\n",
    "# -1 specifies this input will be of unknown shape\n",
    "output = net(X)\n",
    "print(output)"
   ]
  },
  {
   "source": [
    "# Training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "epoch: 1 loss: tensor(0.5315, device='cuda:0', grad_fn=<NllLossBackward>)\nepoch: 2 loss: tensor(0.6937, device='cuda:0', grad_fn=<NllLossBackward>)\nepoch: 3 loss: tensor(0.0424, device='cuda:0', grad_fn=<NllLossBackward>)\nepoch: 4 loss: tensor(0.1731, device='cuda:0', grad_fn=<NllLossBackward>)\nepoch: 5 loss: tensor(0.0086, device='cuda:0', grad_fn=<NllLossBackward>)\n"
    }
   ],
   "source": [
    "net.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for data in trainset:\n",
    "        # data is a batch of features and labels\n",
    "        X, y = data\n",
    "        # X contains 10 images and y contains 10 integers in those images\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        net.zero_grad()\n",
    "        # clears old gradients from the last step\n",
    "        output = net(X.view(-1, 28*28))\n",
    "        loss = F.nll_loss(output, y)\n",
    "        loss.backward()\n",
    "        # backpropogate loss and get direction in which weights will move by computing derivative(gradient)\n",
    "        optimizer.step()\n",
    "        # this will adjust the weights\n",
    "    print(\"epoch: \" + str(epoch+1) + \" loss: \" + str(loss))"
   ]
  },
  {
   "source": [
    "# Testing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy:  0.976\n"
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    #  set all the requires_grad flag to false\n",
    "    for data in testset:\n",
    "        X, y = data\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        output = net(X.view(-1, 784))\n",
    "        for idx, i in enumerate(output):\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "print(\"Accuracy: \", round(correct/total, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1\n"
    }
   ],
   "source": [
    "# getting predictions\n",
    "\n",
    "output = torch.argmax(net(X[0].view(-1, 784))[0]).cpu()\n",
    "output = output.detach().numpy()\n",
    "print(output)"
   ]
  }
 ]
}